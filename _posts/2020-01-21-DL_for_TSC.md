---
title: "Deep Learning for Time Series Classification: InceptionTime"
date: 2019-09-20
tags: [deep learning, keras, convnets]
excerpt: New Deep Learning (GoogleNet-like) model for Time Series Classification
mathjax: "true"
---
(in progress)
Medium Link
{: .text-center}

![inception_module]({{ site.url }}{{ site.baseurl }}/images/dl_for_tsc_figures/inception_module.png){:height="50%" width="100%"}*Fig. 1: The Inception module of InceptionTime.
{: .text-center}*

## Index
1. Motivation
2. Machine Learning for Time Series Classification
3. Best Deep Learning practices for Time Series Classification: InceptionTime
4. Understanding InceptionTime
5. Conclusion

# 1. Motivation

Time series data have always been of major interest to financial services, and now with the rise of real-time applications, other areas such as retail and programmatic advertising are turning their attention to time-series data driven applications. In the last couple of years, several key players in cloud services, such as Apache Kafka and Apache Spark, have released new products for processing time series data. It is therefore of great interest to understand the role and potentials of Machine Learning (ML) in this rising field. 

In this article I discuss the (very) recent discoveries on Time Series Classification (TSC) with Deep Learning, by following a series of publications from the authors of [[1]](https://arxiv.org/abs/1809.04356). 

# 2. Machine Learning for Time Series Classification

## Defining the problem:

TSC is the area of ML interested in learning how to assign labels to time series. To be more concrete, we are interested in training an ML model which when fed with a series of data points indexed in time order (e.g. the historical data of a financial asset), it outputs labels (e.g. the industry sector of the asset).

More formally, let $$(X, y)$$ be a training instance with $$T$$ observations $$(X^1,\dots,X^T)\equiv X$$ (the time series) and a discrete class variable $$y$$ which takes $$k$$ possible values (the labels). A dataset $$S$$ is a set of $$N$$ such training instances: $$S= \{ (X_{(1)}, y_{(1)}),\dots, (X_{(N)}, y_{(N)}) \}$$. The task of classifying time series data consists of learning a classifier on $S$ in order to map from the space of possible inputs $$\{X\}$$ to a probability distribution over the labels $$\{y^1,\dots, y^k\}$$.

## Do we really need DL?

It is always important to remind ourselves that DL is nothing but a set of tools for solving problems, and although DL can be very powerful, that doesn't mean that we should blindly apply DL techniques to every single problem out there. After all, training and tuning a neural network can be very time-consuming so it is always a good practice to test the performance of other ML models and then seek for any potential shortcomings.

Oftentimes the nature of a problem is determined by the data itself; in our case, the way one chooses to process and classify a time series depends highly on the length and statistics of the data. That being said, let us run a quick dimensional analysis to estimate the complexity of our problem. 

Suppose that we wish to learn a one-nearest neighbor classifier for our TSC problem (which is pretty common in the literature). Now given a dataset of $$N$$ time series of length $$T$$, we must compute some sort of a distance measure for $$\binom{N}{2}=N(N-1)/2$$ unique pairs. Moreover, in order to find the "optimal distance" between two time series $$X_{(1)}$$ and $$X_{(2)}$$, we must compute the $$T\times T$$ point-wise distance matrix $$M^{ij}=(X_{(1)}^i-X_{(2)}^j)^2$$ for every unique pair of training instances and then seek for the path which optimizes our objective function. As explained in [[2]](https://arxiv.org/pdf/1602.01711.pdf), there are several optimization algorithms in the literature for this setup, and they all have complexity $$\mathcal{O}(N^2\cdot T^c)$$ with $$c=3$$ or $$4$$. Evidently, **the length of the time series can really hurt the computational speed.** However for certain types of data, this problem can be alleviated without digging into sophisticated machine learning models such as deep neural networks.


In signal processing, a complex signal is analyzed by decomposing the signal into a series of "elementary" signals, called *Fourier modes*. For instance, the square wave below can be approximated by three sinusoidal signals of distinct frequencies $$(f_1,f_2,f_3)=(\omega,3\omega,5\omega)$$, for some constant angular frequency $$\omega$$. 

Fig. 2: The Fourier series expansion of a square wave (red line). Here I present only the first three modes (blue dashed lines) and their addition (green line). Hopefully, it is not hard to see that by adding the next modes the series quickly converges to a square wave.

By taking the linear sum of these signals, we can reconstruct our original signal: 

$$\text{Square Wave}(t)= W^1 \cdot \sin(f_1 t)+W^2 \cdot \sin(f_2 t)+W^3 \cdot \sin(f_3 t)+\dots ,$$

where the coefficients $$(W^1, W^2, W^3) = (1, 1/3, 1/5)$$ specify the *weight* that each mode contributes to the square wave.

Now consider a dataset within which any time series, originally represented by a series of $$T$$ time-ordered data points, can also be represented by a weight vector in the space spanned by the three elementary frequency modes:

$$ X=(X^1,\dots, X^T ) \longrightarrow W=(W^1, W^2, W^3,\dots) .$$

Going from the "time" representation to the "frequency" representation of our time series data is called *Fourier transformation*, and though the Fourier space in theory is infinite-dimensional (rather than 3-dimensional), we can apply various approximation techniques to truncate the Fourier series down to finite dimensions. Most importantly, **we can reduce the $$T$$-dimensional representation of our time series data, to a number of dimensions (in Fourier space) that makes our classification problem computationally trackable.** Overall, we can apply Fourier transformation during the data pre-processing phase to convert the input time series into weight vectors, and thereafter proceed by building our classification model (e.g. a 1-nearest neighbors classifier). Working with such "well-behaved" time series we can achieve high performance without the use of DL.

Now the aforementioned processing method **assumed** that any input signal can be approximated by a Fourier series of elementary (harmonic) functions. However a lot of real-world time-series data are so noisy (e.g. financial data) that do not admit such an elegant decomposition (or any sort of mathematical pre-processing). It is precisely for this type of data that DL comes to the rescue: **letting the model learn how to process time series data on its own is a more promising solution when dealing with unstructured noisy data.**

# 3. Best DL practices for TSC: InceptionTime

As of today, there are two state-of-the-art DL models for TSC. The oldest model, called HIVE-COTE [[3]](https://core.ac.uk/download/pdf/77027925.pdf), is based on the nearest neighbor algorithm coupled with the Dynamic Time Warping similarity measure. Although this algorithm has achieved an outstanding performance on the benchmark datasets [[4]](https://www.cs.ucr.edu/~eamonn/time_series_data/), it suffers from $$\mathcal{O}(N^2\cdot T^4)$$ time complexity. Recently the authors of [[5]](https://arxiv.org/abs/1909.04939), introduced a deep Convolutional Neural Network (CNN), called InceptionTime, which not only outperforms the accuracy of HIVE-COTE but it is also substantially faster. **InceptionTime's high accuracy together with its scalability renders it the perfect candidate for product development!**

To this end, let us present the most important components of InceptionTime and how these are implemented in Keras.

## 3.1 The Input Layer

In general, each data observation $$X^i$$ $$(i=1,\dots,T)$$ of a time series $$X$$ can be a list of one or more data measurements, i.e. $$X^i = ( {X_1}^i,\dots,{X_M}^i )$$ for $$M$$ data measurements, all taken at the $$i$$th time instance. For example, the velocity of a particle moving in 3D space consists of three spatial components: $$\vec V=(V_1, V_2, V_3)$$. Keeping track of the velocity of the particle for $$T$$ seconds, with one observation per second, amounts to collecting the series of data: $$(\vec {V}^1,\dots, \vec {V}^T)$$.

**Definition 1:** An $$M$$-dimensional *Multivariate* Time Series (MTS) $$X= (\vec {X}^1,\dots, \vec {X}^T)$$ consists of $$T$$ ordered elements $$\vec X^i \in \mathbb{R}^M$$.

**Definition 2:** A *Univariate* time series $$X$$ of length $$T$$ is simply an MTS with $$M=1$$, i.e. $$\vec {X}^i\to X^i \in \mathbb{R}$$ and $$X= (X^1,\dots, X^T )$$.

Like in image classification problems, we can think of the input MTS as an array of shape $$(1, T, M)$$, with $$M$$ denoting the number of channels (the depth). In fact, it is convenient to suppress the width of the inputs and work directly with an ```input_shape = (T, M)```.

## 3.2 The Inception Module

The major building block of InceptionTime is the inception module, shown in the figure below:

Fig. 3: The inception module of InceptionTime. The first number in the boxes indicates the kernel size while the second indicates the size of the stride. "(S)" specifies the type of padding, i.e. "same".

This consists of the following layers:
- A *bottleneck layer* to reduce the dimensionality (i.e. the depth) of the inputs. This cuts the computational cost and the number of parameters, speeding up training and improving generalization.
- The output of the bottleneck is fed to three *one-dimensional convolutional layers* of kernel size 10, 20 and 40.  
- The input of the inception module is also passed through a *Max Pooling layer* of size 3 and in turn, through a *bottleneck layer*.
- The last layer is a *depth concatenation layer* where the outputs of the four convolutional layers at step 2 are concatenated along the depth dimension.
All layers (excluding the concatenation layer) have *stride* 1 and "same" *padding*. In addition, all convolutional layers come with 32 *filters*.

## Keras Implementation
``` python
class InceptionModule(keras.layers.Layer):

    def __init__(self, num_filters=32, activation='relu', **kwargs):
        super().__init__(**kwargs)
        self.num_filters = num_filters
        self.activation = keras.activations.get(activation)  

    def _default_Conv1D(self, filters, kernel_size):
        return keras.layers.Conv1D(filters=filters, 
                                   kernel_size=kernel_size, 
                                   strides=1, 
                                   activation='relu', 
                                   use_bias=False)

    def call(self, inputs):
        # Step 1
        Z_bottleneck = self._default_Conv1D(filters=self.num_filters, kernel_size=1)(inputs)
        Z_maxpool = keras.layers.MaxPool1D(pool_size=3, strides=1, padding='same')(inputs)

        # Step 2
        Z1 = self._default_Conv1D(filters=self.num_filters, kernel_size=10)(Z_bottleneck)
        Z2 = self._default_Conv1D(filters=self.num_filters, kernel_size=20)(Z_bottleneck)
        Z3 = self._default_Conv1D(filters=self.num_filters, kernel_size=40)(Z_bottleneck)
        Z4 = self._default_Conv1D(filters=self.num_filters, kernel_size=1)(Z_maxpool)

        # Step 3
        Z = keras.layers.Concatenate(axis=2)([Z1, Z2, Z3, Z4])
        Z = keras.layers.BatchNormalization()(Z)

        return self.activation(Z)
```

# 3.3 The Inception Network

The network architecture of InceptionTime highly resembles to that of GoogleNet's [[6]](https://arxiv.org/pdf/1409.4842.pdf). In particular, the network consists of a series of Inception modules followed by a Global Average Pooling layer and a Dense layer with a softmax activation function.

Fig. 4: The Inception network for time series classification.

However InceptionTime introduces an additional element within its network's layers: residual connections at every third inception module.

Fig. 5: Residual Connections in the Inception network.

## Keras Implementation

```python
def shortcut_layer(inputs, Z_inception):
    # create shortcut connection
    Z_shortcut = keras.layers.Conv1D(filters=int(out_tensor.shape[-1]), kernel_size=1,
                                     padding='same', use_bias=False)(inputs)
    Z_shortcut = keras.layers.BatchNormalization()(Z_shortcut)

    # add shortcut to inception
    Z = keras.layers.Add()([Z_shortcut, Z_inception])

    return keras.layers.Activation('relu')(Z)

def build_model(input_shape, num_classes, num_modules=6):
    # create series of Inception Modules with shortcuts 
    input_layer = keras.layers.Input(input_shape)
    Z = input_layer
    Z_residual = input_layer

    for i in range(num_modules):

        Z = InceptionModule()(Z)
        if i % 3 == 2:
            Z = shortcut_layer(Z_residual, Z)
            Z_residual = Z

    gap_layer = keras.layers.GlobalAveragePooling1D()(Z)
    output_layer = keras.layers.Dense(num_classes, activation='softmax')(gap_layer)

    model = keras.models.Model(inputs=input_layer, outputs=output_layer)
    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(),
                  metrics=['accuracy'])

    return model
```

# 3.4 InceptionTime: a neural network ensemble for TSC

As explained in [[5]](https://arxiv.org/abs/1909.04939), it turns out that a single Inception network exhibits high variance in accuracy. This is probably because of the variability associated to the random weight initialization together with the stochastic optimization process itself. In order to overcome this instability, the proposed state-of-the-art InceptionTime model is actually **an ensemble of 5 Inception networks**, with each prediction given an even weight (see [[7]](https://arxiv.org/abs/1903.06602) for more on deep neural network ensembles for TSC). The full implementation of the model can be found on **github**.

# 4. Understanding InceptionTime

As it was mentioned earlier, InceptionTime was primarily inspired by CNNs for computer vision problems, and we therefore expect our model to learn features in a similar fashion. For example, in image classification the neurons in the bottom layers learn to identify low-level (local) features such as lines, while the neurons in higher layers learn to detect high-level (global) features such as shapes (e.g. eyes). Similarly, we expect the bottom-layer neurons of InceptionTime to capture the local structure of a time series such as lines and curves, and the top-layer neurons to identify various shape patterns such as "valleys" and "hills". 

Fig. 6: The receptive field of neurons in filters.

The region of the input signal that a neuron depends on is called the **receptive field** of that particular neuron. In object recognition, larger receptive fields are used to capture more context. It is therefore natural to pick larger receptive fields when working with very long time series data so that our InceptionTime will learn to detect larger patterns.

# 5. Conclusion
An important aspect in TSC is the length of the time series as this can slow down training. Although there are various mathematical  processing schemes that one can follow to tackle such a problem, InceptionTime is the leading algorithm for TSC, especially for long noisy time series data.

InceptionTime is an ensemble of CNNs which learns to identify local and global shape patterns within a time series dataset (i.e. low- and high-level features). Different experiments [[5]](https://arxiv.org/abs/1909.04939) have shown that **InceptionTime's time complexity grows linearly with both the training set size and the time series length**, i.e. $$\mathcal{O}(N \cdot T)$$! Overall, InceptionTime has put TSC problems on  the same footing with image classification problems, and it is therefore exciting to explore its different applications in the industry sector.

In an upcoming post, I will discuss how I used InceptionTime to classify and cluster financial assets based on different attributes, such as industry sector/class, location and performance.

# References

[[1]](https://arxiv.org/abs/1809.04356) Deep learning for time series classification: a review <br />
[[2]](https://arxiv.org/pdf/1602.01711.pdf) The Great Time Series Classification Bake Off: An Experimental Evaluation of Recently Proposed Algorithms. Extended Version <br />
[[3]](https://core.ac.uk/download/pdf/77027925.pdf) HIVE-COTE: The Hierarchical Vote Collective of Transformation-based Ensembles for Time Series Classification <br />
[[4]](https://www.cs.ucr.edu/~eamonn/time_series_data/) UCR Time Series Classification Archive <br />
[[5]](https://arxiv.org/abs/1909.04939) InceptionTime: Finding AlexNet for Time Series Classification <br />
[[6]](https://arxiv.org/pdf/1409.4842.pdf) Going deeper with convolutions (GoogleNet) <br />
[[7]](https://arxiv.org/abs/1903.06602) Deep Neural Network Ensembles for Time Series Classification



